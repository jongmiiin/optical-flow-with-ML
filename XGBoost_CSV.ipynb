{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nctSvoYqyd8c",
        "outputId": "57899e85-f9f3-45fa-9f62-656ea2d2ae63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-gLAb3Tyf87"
      },
      "outputs": [],
      "source": [
        "# 모듈 임포트\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import csv\n",
        "import subprocess\n",
        "\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LfXERxcyhrL"
      },
      "outputs": [],
      "source": [
        "# 딕셔너리 & 배열 생성\n",
        "\n",
        "# 1) path_lists.json 불러오기\n",
        "SAVE_PATH = \"/content/drive/MyDrive/ML/path_lists.json\"\n",
        "with open(SAVE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "mp4_paths  = data[\"mp4_paths\"]\n",
        "json_paths = data[\"json_paths\"]\n",
        "\n",
        "# 2) base별 매핑\n",
        "mp4_map  = {os.path.splitext(os.path.basename(p))[0]: p for p in mp4_paths}\n",
        "json_map = {os.path.splitext(os.path.basename(p))[0]: p for p in json_paths}\n",
        "\n",
        "# 3) 교집합된 base 정렬\n",
        "bases = sorted(set(mp4_map) & set(json_map))\n",
        "\n",
        "# 4) pairs를 튜플 리스트로 생성\n",
        "pairs = [\n",
        "    (b, mp4_map[b], json_map[b])\n",
        "    for b in bases\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63SLEVFyyjj7"
      },
      "outputs": [],
      "source": [
        "# 파일 경로 설정 및 폴더 생성\n",
        "\n",
        "CSV_PATH = \"/content/drive/MyDrive/ML/of_results.csv\"\n",
        "DONE_MARK = \".done\"\n",
        "OUT_DIR = \"/content/markers/\"\n",
        "os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwQxdkklyk2d"
      },
      "outputs": [],
      "source": [
        "# === Optical Flow 함수 ===\n",
        "lk_params = dict(\n",
        "    winSize=(15,15), maxLevel=2,\n",
        "    criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        ")\n",
        "GRID_SPACING = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAHuINvHyl_E"
      },
      "outputs": [],
      "source": [
        "# 격자점 생성\n",
        "def generate_grid_points(w, h, spacing):\n",
        "    offset = spacing // 2\n",
        "    pts = []\n",
        "    for y in range(offset, h-offset, spacing):\n",
        "        for x in range(offset, w-offset, spacing):\n",
        "            pts.append([[x,y]])\n",
        "    return np.array(pts, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yb55twWyna7"
      },
      "outputs": [],
      "source": [
        "# OF 계산 후 특징점 추출\n",
        "def compute_of_stats_from_array(gray_frames):\n",
        "    \"\"\"\n",
        "    gray_frames: NumPy array shape (45, H, W)\n",
        "    returns: 18차원 리스트 [mean_cnt, std_cnt, mean_vx, std_vx, ... std_angle]\n",
        "    \"\"\"\n",
        "    h, w = gray_frames.shape[1:]\n",
        "    old_gray = gray_frames[0]\n",
        "    p0 = generate_grid_points(w, h, GRID_SPACING)\n",
        "    stats_list = []\n",
        "    for i in range(1, gray_frames.shape[0]):\n",
        "        frame_gray = gray_frames[i]\n",
        "        p1, st, _ = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "        if p1 is None:\n",
        "            stats_list.append([0]*9)\n",
        "            continue\n",
        "        else:\n",
        "            good = st.flatten()==1\n",
        "            p1_flat = p1.reshape(-1, 2)\n",
        "            p0_flat = p0.reshape(-1, 2)\n",
        "            mv = p1_flat[good] - p0_flat[good]\n",
        "            dx, dy = mv[:,0], mv[:,1]\n",
        "            angs = np.degrees(np.arctan2(dy, dx))\n",
        "            mask = (angs>-130)&(angs<-30)&(np.linalg.norm(mv,axis=1)>5)\n",
        "            mv = mv[mask]\n",
        "            if mv.size:\n",
        "                ang2 = np.degrees(np.arctan2(mv[:,1], mv[:,0]))\n",
        "                ma = ang2.mean(); df = np.abs(ang2-ma)\n",
        "                df = np.where(df>180,360-df,df)\n",
        "                mv = mv[df<40]\n",
        "            cnt = mv.shape[0]\n",
        "            if cnt:\n",
        "                vx, vy = mv[:,0], mv[:,1]\n",
        "                sp = np.linalg.norm(mv,axis=1)\n",
        "                ang3 = np.degrees(np.arctan2(vy,vx))\n",
        "                stats_list.append([\n",
        "                    cnt,\n",
        "                    float(vx.mean()), float(vy.mean()),\n",
        "                    float(vx.std()),   float(vy.std()),\n",
        "                    float(sp.mean()), float(sp.std()),\n",
        "                    float(ang3.mean()), float(ang3.std())\n",
        "                ])\n",
        "            else:\n",
        "                stats_list.append([0]*9)\n",
        "        old_gray = frame_gray\n",
        "        p0 = generate_grid_points(w, h, GRID_SPACING)\n",
        "\n",
        "    arr = np.array(stats_list)\n",
        "    summary = []\n",
        "    for c in range(arr.shape[1]):\n",
        "        summary += [ float(arr[:,c].mean()), float(arr[:,c].std()) ]\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpquKidl_9tn"
      },
      "outputs": [],
      "source": [
        "# ffmpeg 변환\n",
        "def load_segment_as_gray(mp4_path, start_sec, duration_sec):\n",
        "    \"\"\"\n",
        "    - start_sec: float, 시작 시각 (초)\n",
        "    - duration_sec: float, 길이 (초)\n",
        "    returns: np.ndarray of shape (frames, H, W), dtype=uint8\n",
        "    \"\"\"\n",
        "    # FFmpeg 필터: fps=30 (60->30), scale=1080:720, format=gray\n",
        "    cmd = [\n",
        "      \"ffmpeg\",\n",
        "      \"-ss\", f\"{start_sec:.3f}\",\n",
        "      \"-i\", mp4_path,\n",
        "      \"-t\", f\"{duration_sec:.3f}\",\n",
        "      \"-vf\", \"fps=30,scale=1080:720,format=gray\",\n",
        "      \"-pix_fmt\", \"gray\",   # 1채널 8bit\n",
        "      \"-f\", \"rawvideo\",     # raw frame pipe\n",
        "      \"pipe:1\"\n",
        "    ]\n",
        "    # 프로세스 생성\n",
        "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    # 예상 프레임 수\n",
        "    num_frames = int(round(duration_sec * 30))\n",
        "    H, W = 720, 1080\n",
        "    expected_bytes = num_frames * H * W\n",
        "\n",
        "    # 파이프에서 한 번에 읽기\n",
        "    raw = b\"\"\n",
        "    while len(raw) < expected_bytes:\n",
        "        chunk = p.stdout.read(expected_bytes - len(raw))\n",
        "        if not chunk:\n",
        "            break\n",
        "        raw += chunk\n",
        "    p.stdout.close()\n",
        "    p.wait()\n",
        "\n",
        "    if len(raw) != expected_bytes:\n",
        "        raise RuntimeError(f\"읽은 바이트가 예상과 다릅니다. {len(raw)}/{expected_bytes}\")\n",
        "\n",
        "    # NumPy 배열로 변환\n",
        "    arr = np.frombuffer(raw, dtype=np.uint8)\n",
        "    return arr.reshape(num_frames, H, W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLkWkOxnyvli"
      },
      "outputs": [],
      "source": [
        "def process_one(args):\n",
        "    base, mp4_path, json_path = args\n",
        "\n",
        "    # 1) JSON 로드\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    s60   = data[\"sensordata\"].get(\"fall_start_frame\", 0)\n",
        "    e60   = data[\"sensordata\"].get(\"fall_end_frame\",   0)\n",
        "    total = data[\"scene_info\"].get(\"scene_length\",    600)  # 60fps 프레임 수\n",
        "\n",
        "    # 2) 윈도우 설정 (1.5초)\n",
        "    window_sec = 1.5\n",
        "    half_sec   = window_sec / 2.0\n",
        "\n",
        "    # 3) 세그먼트 리스트 구성\n",
        "    segments = []\n",
        "    if s60 > 0 and e60 > 0:\n",
        "        # 낙상: 중앙 구간\n",
        "        mid60      = (s60 + e60) / 2.0\n",
        "        mid_time   = mid60 / 60.0\n",
        "        start_time = max(mid_time - half_sec, 0.0)\n",
        "        segments.append((start_time, window_sec, 1, 0))\n",
        "    else:\n",
        "        # 비낙상: 랜덤 3개\n",
        "        max_start = total / 60.0 - window_sec\n",
        "        for sid in range(3):\n",
        "            st = random.uniform(0.0, max_start)\n",
        "            segments.append((st, window_sec, 0, sid))\n",
        "\n",
        "    rows = []\n",
        "    for start_time, duration, label, sid in segments:\n",
        "        key    = (base, sid)\n",
        "        marker = os.path.join(OUT_DIR, f\"{base}_{sid}{DONE_MARK}\")\n",
        "        if key in processed or os.path.exists(marker):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # 4) FFmpeg → 파이프 → NumPy 로 그레이 프레임 읽기\n",
        "            gray_np = load_segment_as_gray(mp4_path, start_time, duration)\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"⚠️ FFmpeg pipe failed for {base}_{sid}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 5) OF 통계 계산\n",
        "        stats = compute_of_stats_from_array(gray_np)\n",
        "        rows.append([base, sid, label] + stats)\n",
        "\n",
        "        # 6) 완료 마커\n",
        "        open(marker, 'w').close()\n",
        "\n",
        "    # 7) CSV 저장\n",
        "    if rows:\n",
        "        with open(CSV_PATH, 'a', newline='') as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerows(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGcnh7JYyxK5",
        "outputId": "66ba2728-883c-4857-fcdb-b7da6450f131"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing videos:  30%|███       | 2593/8592 [3:02:40<8:30:33,  5.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ FFmpeg pipe failed for 01882_Y_A_N_C3_1: 읽은 바이트가 예상과 다릅니다. 34214400/34992000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing videos: 100%|██████████| 8592/8592 [10:12:33<00:00,  4.28s/it]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    for args in tqdm(pairs, total=len(pairs), desc=\"Processing videos\"):\n",
        "        process_one(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
