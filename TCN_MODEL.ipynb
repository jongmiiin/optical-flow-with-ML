{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-WhTFFXBXVF",
        "outputId": "fde65cc1-236e-48f3-c329-50cf2f12b2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16BF3_V8FYx2",
        "outputId": "a6cb8621-4250-4de3-cd0b-494bdd78620d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 1) GPU 환경용 패키지 설치 (한 번만 실행)\n",
        "!pip install --upgrade torch torchvision torchaudio \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "!pip install pytorch-tcn scikit-learn --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByoqKJwVVEZf",
        "outputId": "d7e7b8c6-0bb6-4755-95cc-0e6c7ba61de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# 2) 라이브러리 임포트 테스트\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "# ──────────────────────────────────────────"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLiS2FYaFZ_T"
      },
      "outputs": [],
      "source": [
        "# 2) 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pspAmG29Fcq0"
      },
      "outputs": [],
      "source": [
        "# 3) CSV 로컬 복사 (한 번만 실행)\n",
        "# Colab 런타임에서만 한 번 실행해주세요.\n",
        "!cp /content/drive/MyDrive/Capstone/GrayScale/features_tcn.csv /content/\n",
        "\n",
        "# 3) 데이터 로드 및 전처리\n",
        "df = pd.read_csv('/content/TCN_features.csv')  # git-hub에서는 파일 용량 제한 때문에 T/F를 분리하여 올려 놓은 상태\n",
        "df = df.dropna(subset=['T/F']).reset_index(drop=True)\n",
        "\n",
        "# 3-1) X, y 생성\n",
        "feat_cols = [f'feat_{i}' for i in range(308)]\n",
        "X = df[feat_cols].values.reshape(-1, 44, 7)\n",
        "y = df['T/F'].astype(int).values\n",
        "\n",
        "# 3-2) 특성별 표준화\n",
        "scaler = StandardScaler().fit(X.reshape(-1, 7))\n",
        "X_scaled = scaler.transform(X.reshape(-1, 7)).reshape(-1, 44, 7)\n",
        "\n",
        "# 3-3) 학습/검증 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezG9zVhdhGeR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# y 는 이미 df['T/F'].astype(int).values 로 정의되어 있으므로 그대로 사용\n",
        "indices = np.arange(len(df))\n",
        "\n",
        "# 인덱스와 y를 함께 split\n",
        "train_idx, test_idx, _, _ = train_test_split(\n",
        "    indices, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# test 세트에 해당하는 파일명 추출\n",
        "test_filenames = df.loc[test_idx, '파일명'].values\n",
        "print(test_filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2X6i80Fon74",
        "outputId": "d18291b4-c12a-40b9-fb4b-01aa8e71cbbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 전체 데이터\n",
            "총 개수: 30610\n",
            "  클래스 0: 15327개 (50.1%)\n",
            "  클래스 1: 15283개 (49.9%)\n",
            "\n",
            "🧠 학습 데이터\n",
            "총 개수: 24488\n",
            "  클래스 0: 12262개 (50.1%)\n",
            "  클래스 1: 12226개 (49.9%)\n",
            "\n",
            "🧪 테스트 데이터\n",
            "총 개수: 6122\n",
            "  클래스 0: 3065개 (50.1%)\n",
            "  클래스 1: 3057개 (49.9%)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def print_data_distribution(y, y_train, y_test):\n",
        "    total_counter = Counter(y)\n",
        "    train_counter = Counter(y_train)\n",
        "    test_counter  = Counter(y_test)\n",
        "\n",
        "    print(\"📦 전체 데이터\")\n",
        "    print(f\"총 개수: {len(y)}\")\n",
        "    for k in sorted(total_counter.keys()):\n",
        "        print(f\"  클래스 {k}: {total_counter[k]}개 ({(total_counter[k]/len(y))*100:.1f}%)\")\n",
        "    print()\n",
        "\n",
        "    print(\"🧠 학습 데이터\")\n",
        "    print(f\"총 개수: {len(y_train)}\")\n",
        "    for k in sorted(train_counter.keys()):\n",
        "        print(f\"  클래스 {k}: {train_counter[k]}개 ({(train_counter[k]/len(y_train))*100:.1f}%)\")\n",
        "    print()\n",
        "\n",
        "    print(\"🧪 테스트 데이터\")\n",
        "    print(f\"총 개수: {len(y_test)}\")\n",
        "    for k in sorted(test_counter.keys()):\n",
        "        print(f\"  클래스 {k}: {test_counter[k]}개 ({(test_counter[k]/len(y_test))*100:.1f}%)\")\n",
        "\n",
        "# 사용 예시\n",
        "print_data_distribution(y, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp7-7B1CGHs3"
      },
      "outputs": [],
      "source": [
        "# 4) Dataset & DataLoader\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float).permute(0,2,1)  # (B, C, L)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(SequenceDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(SequenceDataset(X_test,  y_test),  batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10tYRmNdGI5I"
      },
      "outputs": [],
      "source": [
        "# 5) TCNModel 정의 (채널·깊이·드롭아웃)\n",
        "import torch.nn as nn\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tcn1 = TemporalConv1d(7,  64, kernel_size=3, dilation=1, padding=0)\n",
        "        self.tcn2 = TemporalConv1d(64, 64, kernel_size=3, dilation=2, padding=0)\n",
        "        self.tcn3 = TemporalConv1d(64, 64, kernel_size=3, dilation=4, padding=0)\n",
        "        self.tcn4 = TemporalConv1d(64, 64, kernel_size=3, dilation=8, padding=0)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc   = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.tcn1(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn2(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn3(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn4(x)); x = self.dropout(x)\n",
        "        out = x[:, :, -1]                   # 마지막 타임스텝\n",
        "        return self.fc(out).squeeze(-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAA0v76KGKn7"
      },
      "outputs": [],
      "source": [
        "# 6) 디바이스 설정: GPU 고정\n",
        "device = 'cuda'\n",
        "model = TCNModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gf92YloFXUF",
        "outputId": "f9516519-8ee2-43db-dea4-e1d06030c4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 01/65] Train Loss: 0.2542\n",
            "[Epoch 02/65] Train Loss: 0.2043\n",
            "[Epoch 03/65] Train Loss: 0.1956\n",
            "[Epoch 04/65] Train Loss: 0.1903\n",
            "[Epoch 05/65] Train Loss: 0.1844\n",
            "[Epoch 06/65] Train Loss: 0.1779\n",
            "[Epoch 07/65] Train Loss: 0.1771\n",
            "[Epoch 08/65] Train Loss: 0.1720\n",
            "[Epoch 09/65] Train Loss: 0.1696\n",
            "[Epoch 10/65] Train Loss: 0.1654\n",
            "[Epoch 11/65] Train Loss: 0.1627\n",
            "[Epoch 12/65] Train Loss: 0.1605\n",
            "[Epoch 13/65] Train Loss: 0.1604\n",
            "[Epoch 14/65] Train Loss: 0.1578\n",
            "[Epoch 15/65] Train Loss: 0.1513\n",
            "[Epoch 16/65] Train Loss: 0.1471\n",
            "[Epoch 17/65] Train Loss: 0.1429\n",
            "[Epoch 18/65] Train Loss: 0.1445\n",
            "[Epoch 19/65] Train Loss: 0.1409\n",
            "[Epoch 20/65] Train Loss: 0.1396\n",
            "[Epoch 21/65] Train Loss: 0.1387\n",
            "[Epoch 22/65] Train Loss: 0.1394\n",
            "[Epoch 23/65] Train Loss: 0.1367\n",
            "[Epoch 24/65] Train Loss: 0.1376\n",
            "[Epoch 25/65] Train Loss: 0.1324\n",
            "[Epoch 26/65] Train Loss: 0.1325\n",
            "[Epoch 27/65] Train Loss: 0.1343\n",
            "[Epoch 28/65] Train Loss: 0.1320\n",
            "[Epoch 29/65] Train Loss: 0.1335\n",
            "[Epoch 30/65] Train Loss: 0.1305\n",
            "[Epoch 31/65] Train Loss: 0.1267\n",
            "[Epoch 32/65] Train Loss: 0.1273\n",
            "[Epoch 33/65] Train Loss: 0.1267\n",
            "[Epoch 34/65] Train Loss: 0.1260\n",
            "[Epoch 35/65] Train Loss: 0.1237\n",
            "[Epoch 36/65] Train Loss: 0.1252\n",
            "[Epoch 37/65] Train Loss: 0.1256\n",
            "[Epoch 38/65] Train Loss: 0.1230\n",
            "[Epoch 39/65] Train Loss: 0.1220\n",
            "[Epoch 40/65] Train Loss: 0.1239\n",
            "[Epoch 41/65] Train Loss: 0.1236\n",
            "[Epoch 42/65] Train Loss: 0.1233\n",
            "[Epoch 43/65] Train Loss: 0.1220\n",
            "[Epoch 44/65] Train Loss: 0.1195\n",
            "[Epoch 45/65] Train Loss: 0.1193\n",
            "[Epoch 46/65] Train Loss: 0.1212\n",
            "[Epoch 47/65] Train Loss: 0.1156\n",
            "[Epoch 48/65] Train Loss: 0.1174\n",
            "[Epoch 49/65] Train Loss: 0.1174\n",
            "[Epoch 50/65] Train Loss: 0.1166\n",
            "[Epoch 51/65] Train Loss: 0.1167\n",
            "[Epoch 52/65] Train Loss: 0.1189\n",
            "[Epoch 53/65] Train Loss: 0.1162\n",
            "[Epoch 54/65] Train Loss: 0.1165\n",
            "[Epoch 55/65] Train Loss: 0.1142\n",
            "[Epoch 56/65] Train Loss: 0.1150\n",
            "[Epoch 57/65] Train Loss: 0.1138\n",
            "[Epoch 58/65] Train Loss: 0.1178\n",
            "[Epoch 59/65] Train Loss: 0.1147\n",
            "[Epoch 60/65] Train Loss: 0.1151\n",
            "[Epoch 61/65] Train Loss: 0.1130\n",
            "[Epoch 62/65] Train Loss: 0.1100\n",
            "[Epoch 63/65] Train Loss: 0.1125\n",
            "[Epoch 64/65] Train Loss: 0.1153\n",
            "[Epoch 65/65] Train Loss: 0.1124\n"
          ]
        }
      ],
      "source": [
        "# 7) 학습 루프\n",
        "n_epochs = 65\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device).float()\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch:02d}/{n_epochs}] Train Loss: {np.mean(losses):.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36A1ttwDIYbr",
        "outputId": "4eac43dd-9884-4350-b078-9794e97c820e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy: 0.9499\n",
            "Confusion Matrix:\n",
            " [[2914  151]\n",
            " [ 156 2901]]\n"
          ]
        }
      ],
      "source": [
        "# 8) 평가\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        preds = (torch.sigmoid(model(xb)) > 0.5).cpu().long().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(yb.numpy())\n",
        "\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqRJE-FdQK_c",
        "outputId": "88740fc1-6937-4971-a81a-869e8ff0e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델 가중치를 'tcn_model_state.pth'로 저장했습니다.\n"
          ]
        }
      ],
      "source": [
        "# 학습이 끝난 후\n",
        "save_path = \"tcn_model_state.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"모델 가중치를 '{save_path}'로 저장했습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-PqVCv6scZq",
        "outputId": "8bacde76-9e3e-4ee3-a96a-7131e9bca30a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "\n",
        "# 이미 fit() 한 scaler\n",
        "dump(scaler, \"scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uohu-J7fsfWS"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "scaler = load(\"scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UaNE_bvp8Du",
        "outputId": "7ea50f73-3de7-42cd-a3e8-21b8b091594e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측:1, 정답:1\n",
            "예측:0, 정답:0\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:0, 정답:0\n",
            "예측:1, 정답:1\n",
            "예측:1, 정답:1\n",
            "예측:0, 정답:0\n",
            "예측:1, 정답:1\n",
            "예측:0, 정답:0\n",
            "예측:1, 정답:1\n",
            "예측:0, 정답:0\n",
            "예측:0, 정답:0\n",
            "예측:1, 정답:0\n"
          ]
        }
      ],
      "source": [
        "# inference.py\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) 모델 인스턴스 생성\n",
        "model = TCNModel().to(device)\n",
        "\n",
        "# 2) 저장된 가중치 불러오기\n",
        "checkpoint = torch.load(\"tcn_model_state.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# 3) 평가 모드 전환\n",
        "model.eval()\n",
        "\n",
        "for i in range(20):\n",
        "  # 1) NumPy → Tensor, float 타입으로\n",
        "  sample_np = X_test[i]                   # shape: (44, 7)\n",
        "  sample = torch.tensor(sample_np, dtype=torch.float)\n",
        "\n",
        "  # 2) (44,7) → (7,44)로 차원 순서 변경\n",
        "  sample = sample.permute(1, 0)           # shape: (7, 44)\n",
        "\n",
        "  # 3) 배치 차원 추가 → (1,7,44)\n",
        "  sample = sample.unsqueeze(0)            # shape: (1, 7, 44)\n",
        "\n",
        "  # 4) 예측 실행\n",
        "  with torch.no_grad():\n",
        "      sample = sample.to(device)\n",
        "      logits = model(sample)\n",
        "      prob   = torch.sigmoid(logits)\n",
        "      pred_label = (prob > 0.5).long()\n",
        "      print(\"예측:\",end=\"\")\n",
        "      print(pred_label.item(),end=\"\")\n",
        "      print(\", 정답:\",end=\"\")\n",
        "      print(y_test[i])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
