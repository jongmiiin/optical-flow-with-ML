{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-WhTFFXBXVF",
        "outputId": "fde65cc1-236e-48f3-c329-50cf2f12b2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16BF3_V8FYx2",
        "outputId": "a6cb8621-4250-4de3-cd0b-494bdd78620d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 1) GPU í™˜ê²½ìš© íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
        "!pip install --upgrade torch torchvision torchaudio \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "!pip install pytorch-tcn scikit-learn --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByoqKJwVVEZf",
        "outputId": "d7e7b8c6-0bb6-4755-95cc-0e6c7ba61de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# 2) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLiS2FYaFZ_T"
      },
      "outputs": [],
      "source": [
        "# 2) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pspAmG29Fcq0"
      },
      "outputs": [],
      "source": [
        "# 3) CSV ë¡œì»¬ ë³µì‚¬ (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
        "# Colab ëŸ°íƒ€ì„ì—ì„œë§Œ í•œ ë²ˆ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n",
        "!cp /content/drive/MyDrive/Capstone/GrayScale/features_tcn.csv /content/\n",
        "\n",
        "# 3) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "df = pd.read_csv('/content/TCN_features.csv')  # git-hubì—ì„œëŠ” íŒŒì¼ ìš©ëŸ‰ ì œí•œ ë•Œë¬¸ì— T/Fë¥¼ ë¶„ë¦¬í•˜ì—¬ ì˜¬ë ¤ ë†“ì€ ìƒíƒœ\n",
        "df = df.dropna(subset=['T/F']).reset_index(drop=True)\n",
        "\n",
        "# 3-1) X, y ìƒì„±\n",
        "feat_cols = [f'feat_{i}' for i in range(308)]\n",
        "X = df[feat_cols].values.reshape(-1, 44, 7)\n",
        "y = df['T/F'].astype(int).values\n",
        "\n",
        "# 3-2) íŠ¹ì„±ë³„ í‘œì¤€í™”\n",
        "scaler = StandardScaler().fit(X.reshape(-1, 7))\n",
        "X_scaled = scaler.transform(X.reshape(-1, 7)).reshape(-1, 44, 7)\n",
        "\n",
        "# 3-3) í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezG9zVhdhGeR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# y ëŠ” ì´ë¯¸ df['T/F'].astype(int).values ë¡œ ì •ì˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "indices = np.arange(len(df))\n",
        "\n",
        "# ì¸ë±ìŠ¤ì™€ yë¥¼ í•¨ê»˜ split\n",
        "train_idx, test_idx, _, _ = train_test_split(\n",
        "    indices, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# test ì„¸íŠ¸ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ëª… ì¶”ì¶œ\n",
        "test_filenames = df.loc[test_idx, 'íŒŒì¼ëª…'].values\n",
        "print(test_filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2X6i80Fon74",
        "outputId": "d18291b4-c12a-40b9-fb4b-01aa8e71cbbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ ì „ì²´ ë°ì´í„°\n",
            "ì´ ê°œìˆ˜: 30610\n",
            "  í´ë˜ìŠ¤ 0: 15327ê°œ (50.1%)\n",
            "  í´ë˜ìŠ¤ 1: 15283ê°œ (49.9%)\n",
            "\n",
            "ğŸ§  í•™ìŠµ ë°ì´í„°\n",
            "ì´ ê°œìˆ˜: 24488\n",
            "  í´ë˜ìŠ¤ 0: 12262ê°œ (50.1%)\n",
            "  í´ë˜ìŠ¤ 1: 12226ê°œ (49.9%)\n",
            "\n",
            "ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
            "ì´ ê°œìˆ˜: 6122\n",
            "  í´ë˜ìŠ¤ 0: 3065ê°œ (50.1%)\n",
            "  í´ë˜ìŠ¤ 1: 3057ê°œ (49.9%)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def print_data_distribution(y, y_train, y_test):\n",
        "    total_counter = Counter(y)\n",
        "    train_counter = Counter(y_train)\n",
        "    test_counter  = Counter(y_test)\n",
        "\n",
        "    print(\"ğŸ“¦ ì „ì²´ ë°ì´í„°\")\n",
        "    print(f\"ì´ ê°œìˆ˜: {len(y)}\")\n",
        "    for k in sorted(total_counter.keys()):\n",
        "        print(f\"  í´ë˜ìŠ¤ {k}: {total_counter[k]}ê°œ ({(total_counter[k]/len(y))*100:.1f}%)\")\n",
        "    print()\n",
        "\n",
        "    print(\"ğŸ§  í•™ìŠµ ë°ì´í„°\")\n",
        "    print(f\"ì´ ê°œìˆ˜: {len(y_train)}\")\n",
        "    for k in sorted(train_counter.keys()):\n",
        "        print(f\"  í´ë˜ìŠ¤ {k}: {train_counter[k]}ê°œ ({(train_counter[k]/len(y_train))*100:.1f}%)\")\n",
        "    print()\n",
        "\n",
        "    print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°\")\n",
        "    print(f\"ì´ ê°œìˆ˜: {len(y_test)}\")\n",
        "    for k in sorted(test_counter.keys()):\n",
        "        print(f\"  í´ë˜ìŠ¤ {k}: {test_counter[k]}ê°œ ({(test_counter[k]/len(y_test))*100:.1f}%)\")\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "print_data_distribution(y, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp7-7B1CGHs3"
      },
      "outputs": [],
      "source": [
        "# 4) Dataset & DataLoader\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float).permute(0,2,1)  # (B, C, L)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(SequenceDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(SequenceDataset(X_test,  y_test),  batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10tYRmNdGI5I"
      },
      "outputs": [],
      "source": [
        "# 5) TCNModel ì •ì˜ (ì±„ë„Â·ê¹Šì´Â·ë“œë¡­ì•„ì›ƒ)\n",
        "import torch.nn as nn\n",
        "from pytorch_tcn import TemporalConv1d\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tcn1 = TemporalConv1d(7,  64, kernel_size=3, dilation=1, padding=0)\n",
        "        self.tcn2 = TemporalConv1d(64, 64, kernel_size=3, dilation=2, padding=0)\n",
        "        self.tcn3 = TemporalConv1d(64, 64, kernel_size=3, dilation=4, padding=0)\n",
        "        self.tcn4 = TemporalConv1d(64, 64, kernel_size=3, dilation=8, padding=0)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc   = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.tcn1(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn2(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn3(x)); x = self.dropout(x)\n",
        "        x = self.relu(self.tcn4(x)); x = self.dropout(x)\n",
        "        out = x[:, :, -1]                   # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…\n",
        "        return self.fc(out).squeeze(-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAA0v76KGKn7"
      },
      "outputs": [],
      "source": [
        "# 6) ë””ë°”ì´ìŠ¤ ì„¤ì •: GPU ê³ ì •\n",
        "device = 'cuda'\n",
        "model = TCNModel().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gf92YloFXUF",
        "outputId": "f9516519-8ee2-43db-dea4-e1d06030c4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 01/65] Train Loss: 0.2542\n",
            "[Epoch 02/65] Train Loss: 0.2043\n",
            "[Epoch 03/65] Train Loss: 0.1956\n",
            "[Epoch 04/65] Train Loss: 0.1903\n",
            "[Epoch 05/65] Train Loss: 0.1844\n",
            "[Epoch 06/65] Train Loss: 0.1779\n",
            "[Epoch 07/65] Train Loss: 0.1771\n",
            "[Epoch 08/65] Train Loss: 0.1720\n",
            "[Epoch 09/65] Train Loss: 0.1696\n",
            "[Epoch 10/65] Train Loss: 0.1654\n",
            "[Epoch 11/65] Train Loss: 0.1627\n",
            "[Epoch 12/65] Train Loss: 0.1605\n",
            "[Epoch 13/65] Train Loss: 0.1604\n",
            "[Epoch 14/65] Train Loss: 0.1578\n",
            "[Epoch 15/65] Train Loss: 0.1513\n",
            "[Epoch 16/65] Train Loss: 0.1471\n",
            "[Epoch 17/65] Train Loss: 0.1429\n",
            "[Epoch 18/65] Train Loss: 0.1445\n",
            "[Epoch 19/65] Train Loss: 0.1409\n",
            "[Epoch 20/65] Train Loss: 0.1396\n",
            "[Epoch 21/65] Train Loss: 0.1387\n",
            "[Epoch 22/65] Train Loss: 0.1394\n",
            "[Epoch 23/65] Train Loss: 0.1367\n",
            "[Epoch 24/65] Train Loss: 0.1376\n",
            "[Epoch 25/65] Train Loss: 0.1324\n",
            "[Epoch 26/65] Train Loss: 0.1325\n",
            "[Epoch 27/65] Train Loss: 0.1343\n",
            "[Epoch 28/65] Train Loss: 0.1320\n",
            "[Epoch 29/65] Train Loss: 0.1335\n",
            "[Epoch 30/65] Train Loss: 0.1305\n",
            "[Epoch 31/65] Train Loss: 0.1267\n",
            "[Epoch 32/65] Train Loss: 0.1273\n",
            "[Epoch 33/65] Train Loss: 0.1267\n",
            "[Epoch 34/65] Train Loss: 0.1260\n",
            "[Epoch 35/65] Train Loss: 0.1237\n",
            "[Epoch 36/65] Train Loss: 0.1252\n",
            "[Epoch 37/65] Train Loss: 0.1256\n",
            "[Epoch 38/65] Train Loss: 0.1230\n",
            "[Epoch 39/65] Train Loss: 0.1220\n",
            "[Epoch 40/65] Train Loss: 0.1239\n",
            "[Epoch 41/65] Train Loss: 0.1236\n",
            "[Epoch 42/65] Train Loss: 0.1233\n",
            "[Epoch 43/65] Train Loss: 0.1220\n",
            "[Epoch 44/65] Train Loss: 0.1195\n",
            "[Epoch 45/65] Train Loss: 0.1193\n",
            "[Epoch 46/65] Train Loss: 0.1212\n",
            "[Epoch 47/65] Train Loss: 0.1156\n",
            "[Epoch 48/65] Train Loss: 0.1174\n",
            "[Epoch 49/65] Train Loss: 0.1174\n",
            "[Epoch 50/65] Train Loss: 0.1166\n",
            "[Epoch 51/65] Train Loss: 0.1167\n",
            "[Epoch 52/65] Train Loss: 0.1189\n",
            "[Epoch 53/65] Train Loss: 0.1162\n",
            "[Epoch 54/65] Train Loss: 0.1165\n",
            "[Epoch 55/65] Train Loss: 0.1142\n",
            "[Epoch 56/65] Train Loss: 0.1150\n",
            "[Epoch 57/65] Train Loss: 0.1138\n",
            "[Epoch 58/65] Train Loss: 0.1178\n",
            "[Epoch 59/65] Train Loss: 0.1147\n",
            "[Epoch 60/65] Train Loss: 0.1151\n",
            "[Epoch 61/65] Train Loss: 0.1130\n",
            "[Epoch 62/65] Train Loss: 0.1100\n",
            "[Epoch 63/65] Train Loss: 0.1125\n",
            "[Epoch 64/65] Train Loss: 0.1153\n",
            "[Epoch 65/65] Train Loss: 0.1124\n"
          ]
        }
      ],
      "source": [
        "# 7) í•™ìŠµ ë£¨í”„\n",
        "n_epochs = 65\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device).float()\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch:02d}/{n_epochs}] Train Loss: {np.mean(losses):.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36A1ttwDIYbr",
        "outputId": "4eac43dd-9884-4350-b078-9794e97c820e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy: 0.9499\n",
            "Confusion Matrix:\n",
            " [[2914  151]\n",
            " [ 156 2901]]\n"
          ]
        }
      ],
      "source": [
        "# 8) í‰ê°€\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        preds = (torch.sigmoid(model(xb)) > 0.5).cpu().long().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(yb.numpy())\n",
        "\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqRJE-FdQK_c",
        "outputId": "88740fc1-6937-4971-a81a-869e8ff0e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ 'tcn_model_state.pth'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# í•™ìŠµì´ ëë‚œ í›„\n",
        "save_path = \"tcn_model_state.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ '{save_path}'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-PqVCv6scZq",
        "outputId": "8bacde76-9e3e-4ee3-a96a-7131e9bca30a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "\n",
        "# ì´ë¯¸ fit() í•œ scaler\n",
        "dump(scaler, \"scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uohu-J7fsfWS"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "scaler = load(\"scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UaNE_bvp8Du",
        "outputId": "7ea50f73-3de7-42cd-a3e8-21b8b091594e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:1\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:0, ì •ë‹µ:0\n",
            "ì˜ˆì¸¡:1, ì •ë‹µ:0\n"
          ]
        }
      ],
      "source": [
        "# inference.py\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "model = TCNModel().to(device)\n",
        "\n",
        "# 2) ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "checkpoint = torch.load(\"tcn_model_state.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# 3) í‰ê°€ ëª¨ë“œ ì „í™˜\n",
        "model.eval()\n",
        "\n",
        "for i in range(20):\n",
        "  # 1) NumPy â†’ Tensor, float íƒ€ì…ìœ¼ë¡œ\n",
        "  sample_np = X_test[i]                   # shape: (44, 7)\n",
        "  sample = torch.tensor(sample_np, dtype=torch.float)\n",
        "\n",
        "  # 2) (44,7) â†’ (7,44)ë¡œ ì°¨ì› ìˆœì„œ ë³€ê²½\n",
        "  sample = sample.permute(1, 0)           # shape: (7, 44)\n",
        "\n",
        "  # 3) ë°°ì¹˜ ì°¨ì› ì¶”ê°€ â†’ (1,7,44)\n",
        "  sample = sample.unsqueeze(0)            # shape: (1, 7, 44)\n",
        "\n",
        "  # 4) ì˜ˆì¸¡ ì‹¤í–‰\n",
        "  with torch.no_grad():\n",
        "      sample = sample.to(device)\n",
        "      logits = model(sample)\n",
        "      prob   = torch.sigmoid(logits)\n",
        "      pred_label = (prob > 0.5).long()\n",
        "      print(\"ì˜ˆì¸¡:\",end=\"\")\n",
        "      print(pred_label.item(),end=\"\")\n",
        "      print(\", ì •ë‹µ:\",end=\"\")\n",
        "      print(y_test[i])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
